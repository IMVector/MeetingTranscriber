import 'dart:async';
import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:path_provider/path_provider.dart';
import 'package:record/record.dart';
import 'package:path/path.dart' as p;

// Note: dart:typed_data is kept as Uint8List is used in this file

/// éŸ³é¢‘è¾“å…¥è®¾å¤‡ä¿¡æ¯
class AudioInputDevice {
  final String id;
  final String label;

  AudioInputDevice({
    required this.id,
    required this.label,
  });

  @override
  String toString() => label;
}

/// éŸ³é¢‘å½•åˆ¶æœåŠ¡
class AudioRecordingService extends ChangeNotifier {
  final AudioRecorder _recorder = AudioRecorder();

  bool _isRecording = false;
  bool _isPaused = false;
  String? _currentRecordingPath;
  DateTime? _recordingStartTime;
  Duration _recordingDuration = Duration.zero;
  Timer? _durationTimer;

  // éŸ³é¢‘ç”µå¹³
  double _audioLevel = 0.0;
  Timer? _levelTimer;
  StreamSubscription<RecordState>? _stateSubscription;

  // æµå¼éŸ³é¢‘æ•°æ®
  final StreamController<Float32List> _audioStreamController = StreamController<Float32List>.broadcast();
  Stream<Float32List> get audioStream => _audioStreamController.stream;

  // å®æ—¶è½¬å½•ç”¨çš„éŸ³é¢‘ç¼“å†²
  final List<Float32List> _audioBuffer = [];
  static const int _sampleRate = 16000;
  static const int _chunkDurationSeconds = 3; // æ¯3ç§’å¤„ç†ä¸€æ¬¡
  static const int _samplesPerChunk = _sampleRate * _chunkDurationSeconds;

  // PCM æ•°æ®ç¼“å†²ï¼ˆç”¨äºä¿å­˜å½•éŸ³æ–‡ä»¶ï¼‰
  List<int> _pcmBuffer = [];

  // æ–‡ä»¶å†™å…¥æµï¼ˆè¾¹å½•è¾¹å†™ï¼‰
  IOSink? _fileSink;
  int _totalBytesWritten = 0;

  // å®æ—¶è½¬å½•å›è°ƒ
  void Function(Float32List samples)? onAudioChunkReady;

  // æµè®¢é˜…
  StreamSubscription<Uint8List>? _streamSubscription;

  // éŸ³é¢‘è¾“å…¥è®¾å¤‡
  List<AudioInputDevice> _inputDevices = [];
  AudioInputDevice? _selectedDevice;

  // Getters
  bool get isRecording => _isRecording;
  bool get isPaused => _isPaused;
  String? get currentRecordingPath => _currentRecordingPath;
  Duration get recordingDuration => _recordingDuration;
  double get audioLevel => _audioLevel;
  List<AudioInputDevice> get inputDevices => _inputDevices;
  AudioInputDevice? get selectedDevice => _selectedDevice;

  /// è·å–å¯ç”¨çš„éŸ³é¢‘è¾“å…¥è®¾å¤‡åˆ—è¡¨
  Future<List<AudioInputDevice>> getInputDevices() async {
    try {
      final devices = await _recorder.listInputDevices();
      _inputDevices = devices.map((device) {
        return AudioInputDevice(
          id: device.id,
          label: device.label.isNotEmpty ? device.label : 'Unknown Device',
        );
      }).toList();

      // å¦‚æœæ²¡æœ‰é€‰ä¸­è®¾å¤‡ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªè®¾å¤‡
      if (_selectedDevice == null && _inputDevices.isNotEmpty) {
        _selectedDevice = _inputDevices.first;
      }

      notifyListeners();
      return _inputDevices;
    } catch (e) {
      print('âŒ è·å–è¾“å…¥è®¾å¤‡åˆ—è¡¨å¤±è´¥: $e');
      return [];
    }
  }

  /// é€‰æ‹©éŸ³é¢‘è¾“å…¥è®¾å¤‡
  void selectDevice(AudioInputDevice device) {
    _selectedDevice = device;
    notifyListeners();
  }

  /// æ£€æŸ¥å¹¶è¯·æ±‚éº¦å…‹é£æƒé™
  Future<bool> requestPermission() async {
    try {
      // ä½¿ç”¨ record åŒ…çš„æƒé™æ£€æŸ¥ï¼Œåœ¨ macOS ä¸Šæ›´å¯é 
      final hasPermission = await _recorder.hasPermission();
      return hasPermission;
    } catch (e) {
      print('æƒé™æ£€æŸ¥é”™è¯¯: $e');
      // åœ¨ macOS ä¸Šï¼Œå¦‚æœ entitlements é…ç½®æ­£ç¡®ï¼Œç›´æ¥è¿”å› true
      if (Platform.isMacOS) {
        return true;
      }
      return false;
    }
  }

  /// æ£€æŸ¥æ˜¯å¦æœ‰éº¦å…‹é£æƒé™
  Future<bool> hasPermission() async {
    try {
      return await _recorder.hasPermission();
    } catch (e) {
      // åœ¨ macOS ä¸Šï¼Œå¦‚æœ entitlements é…ç½®æ­£ç¡®ï¼Œç›´æ¥è¿”å› true
      if (Platform.isMacOS) {
        return true;
      }
      return false;
    }
  }

  /// å¼€å§‹å½•éŸ³ï¼ˆæ”¯æŒå®æ—¶è½¬å½•ï¼‰
  Future<bool> startRecording({String? outputPath}) async {
    if (_isRecording) {
      print('âš ï¸ å·²ç»åœ¨å½•éŸ³ä¸­');
      return false;
    }

    // æ£€æŸ¥æƒé™
    if (!await requestPermission()) {
      print('âŒ éº¦å…‹é£æƒé™è¢«æ‹’ç»');
      return false;
    }

    try {
      // ç¡®å®šè¾“å‡ºè·¯å¾„
      if (outputPath == null) {
        final appDir = await getApplicationDocumentsDirectory();
        final timestamp = DateTime.now().toIso8601String().replaceAll(':', '-');
        outputPath = p.join(appDir.path, 'recordings', 'recording_$timestamp.wav');
        await Directory(p.dirname(outputPath)).create(recursive: true);
      }

      _currentRecordingPath = outputPath;
      _pcmBuffer.clear();
      _audioBuffer.clear();
      _totalBytesWritten = 0;

      // åˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥ WAV å¤´éƒ¨ï¼ˆé¢„ç•™44å­—èŠ‚ï¼‰
      final file = File(outputPath);
      _fileSink = file.openWrite();
      await _writeWavHeader(_fileSink!, 0); // å…ˆå†™å…¥å ä½å¤´éƒ¨

      // é…ç½®å½•éŸ³å‚æ•°ï¼Œæ”¯æŒé€‰æ‹©è®¾å¤‡
      InputDevice? deviceConfig;
      if (_selectedDevice != null && _selectedDevice!.id.isNotEmpty) {
        deviceConfig = InputDevice(id: _selectedDevice!.id, label: _selectedDevice!.label);
      }

      final config = RecordConfig(
        encoder: AudioEncoder.pcm16bits,
        sampleRate: _sampleRate,
        numChannels: 1,
        device: deviceConfig,
      );

      print('ğŸ¤ å½•éŸ³è®¾å¤‡: ${_selectedDevice?.label ?? "é»˜è®¤è®¾å¤‡"}');

      // ä½¿ç”¨æµå¼å½•éŸ³ä»¥æ”¯æŒå®æ—¶è½¬å½•
      final stream = await _recorder.startStream(config);

      // è®¢é˜…éŸ³é¢‘æµ
      _streamSubscription = stream.listen(
        (data) {
          _handleAudioData(data);
        },
        onError: (error) {
          print('âŒ éŸ³é¢‘æµé”™è¯¯: $error');
        },
      );

      _isRecording = true;
      _isPaused = false;
      _recordingStartTime = DateTime.now();
      _recordingDuration = Duration.zero;

      // å¯åŠ¨è®¡æ—¶å™¨
      _startDurationTimer();
      _startAudioLevelMonitor();

      print('âœ“ å¼€å§‹å½•éŸ³ï¼ˆæµå¼ï¼‰');
      notifyListeners();
      return true;
    } catch (e) {
      print('âŒ å¼€å§‹å½•éŸ³å¤±è´¥: $e');
      // ç¡®ä¿é”™è¯¯æ—¶é‡ç½®çŠ¶æ€
      _isRecording = false;
      _isPaused = false;
      _streamSubscription?.cancel();
      _streamSubscription = null;
      await _fileSink?.close();
      _fileSink = null;
      notifyListeners();
      return false;
    }
  }

  /// å†™å…¥ WAV æ–‡ä»¶å¤´
  Future<void> _writeWavHeader(IOSink sink, int dataSize) async {
    final header = Uint8List(44);
    final headerData = ByteData.sublistView(header);

    // RIFF header
    header.setRange(0, 4, 'RIFF'.codeUnits);
    headerData.setUint32(4, 36 + dataSize, Endian.little);
    header.setRange(8, 12, 'WAVE'.codeUnits);

    // fmt chunk
    header.setRange(12, 16, 'fmt '.codeUnits);
    headerData.setUint32(16, 16, Endian.little);
    headerData.setUint16(20, 1, Endian.little);
    headerData.setUint16(22, 1, Endian.little);
    headerData.setUint32(24, _sampleRate, Endian.little);
    headerData.setUint32(28, _sampleRate * 2, Endian.little);
    headerData.setUint16(32, 2, Endian.little);
    headerData.setUint16(34, 16, Endian.little);

    // data chunk
    header.setRange(36, 40, 'data'.codeUnits);
    headerData.setUint32(40, dataSize, Endian.little);

    sink.add(header);
  }

  /// å¤„ç†éŸ³é¢‘æ•°æ®
  void _handleAudioData(Uint8List data) {
    // å®æ—¶å†™å…¥æ–‡ä»¶ï¼ˆé¿å…å†…å­˜ç¼“å†²è¿‡å¤§ï¼‰
    if (_fileSink != null) {
      _fileSink!.add(data);
      _totalBytesWritten += data.length;
    }

    // åŒæ—¶ä¿å­˜åˆ°å†…å­˜ç¼“å†²ï¼ˆç”¨äºå®æ—¶è½¬å½•ï¼‰
    _pcmBuffer.addAll(data);

    // è½¬æ¢ä¸º Float32 ç”¨äºå®æ—¶è½¬å½•
    final samples = _convertPcm16ToFloat32(data);

    // å‘é€åˆ°æµ
    _audioStreamController.add(samples);

    // æ·»åŠ åˆ°ç¼“å†²åŒºå¹¶æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
    _audioBuffer.add(samples);

    int totalSamples = _audioBuffer.fold(0, (sum, chunk) => sum + chunk.length);
    if (totalSamples >= _samplesPerChunk && onAudioChunkReady != null) {
      // åˆå¹¶ç¼“å†²åŒºä¸­çš„æ‰€æœ‰æ•°æ®
      final combinedSamples = Float32List(totalSamples);
      int offset = 0;
      for (final chunk in _audioBuffer) {
        combinedSamples.setRange(offset, offset + chunk.length, chunk);
        offset += chunk.length;
      }

      // æ¸…ç©ºç¼“å†²åŒº
      _audioBuffer.clear();

      // å›è°ƒå¤„ç†
      onAudioChunkReady!(combinedSamples);
    }

    // æ›´æ–°éŸ³é¢‘ç”µå¹³
    _updateAudioLevelFromSamples(samples);
  }

  /// å°† 16-bit PCM è½¬æ¢ä¸º Float32
  Float32List _convertPcm16ToFloat32(Uint8List data) {
    final sampleCount = data.length ~/ 2;
    final samples = Float32List(sampleCount);

    for (int i = 0; i < sampleCount; i++) {
      final int16 = data[i * 2] | (data[i * 2 + 1] << 8);
      // å¤„ç†æœ‰ç¬¦å·æ•´æ•°
      final signed = int16 > 32767 ? int16 - 65536 : int16;
      samples[i] = signed / 32768.0;
    }

    return samples;
  }

  /// ä»éŸ³é¢‘æ ·æœ¬æ›´æ–°ç”µå¹³
  void _updateAudioLevelFromSamples(Float32List samples) {
    if (samples.isEmpty) return;

    double maxAbs = 0;
    for (final sample in samples) {
      final abs = sample.abs();
      if (abs > maxAbs) maxAbs = abs;
    }

    _audioLevel = maxAbs.clamp(0.0, 1.0);
  }

  /// æš‚åœå½•éŸ³
  Future<bool> pauseRecording() async {
    if (!_isRecording || _isPaused) return false;

    try {
      await _recorder.pause();
      _isPaused = true;
      _stopDurationTimer();
      print('â¸ å½•éŸ³å·²æš‚åœ');
      notifyListeners();
      return true;
    } catch (e) {
      print('âŒ æš‚åœå½•éŸ³å¤±è´¥: $e');
      return false;
    }
  }

  /// ç»§ç»­å½•éŸ³
  Future<bool> resumeRecording() async {
    if (!_isRecording || !_isPaused) return false;

    try {
      await _recorder.resume();
      _isPaused = false;
      _startDurationTimer();
      print('â–¶ å½•éŸ³å·²ç»§ç»­');
      notifyListeners();
      return true;
    } catch (e) {
      print('âŒ ç»§ç»­å½•éŸ³å¤±è´¥: $e');
      return false;
    }
  }

  /// åœæ­¢å½•éŸ³
  Future<String?> stopRecording() async {
    debugPrint('ğŸ” [AUDIO] 1. stopRecording å¼€å§‹');
    if (!_isRecording) return null;

    try {
      // åœæ­¢æµè®¢é˜…
      debugPrint('ğŸ” [AUDIO] 2. åœæ­¢æµè®¢é˜…');
      await _streamSubscription?.cancel();
      _streamSubscription = null;
      debugPrint('ğŸ” [AUDIO] 3. æµè®¢é˜…å·²åœæ­¢');

      // åœæ­¢å½•éŸ³å™¨
      debugPrint('ğŸ” [AUDIO] 4. åœæ­¢å½•éŸ³å™¨');
      await _recorder.stop();
      debugPrint('ğŸ” [AUDIO] 5. å½•éŸ³å™¨å·²åœæ­¢');

      _isRecording = false;
      _isPaused = false;

      _stopDurationTimer();
      _stopAudioLevelMonitor();
      debugPrint('ğŸ” [AUDIO] 6. è®¡æ—¶å™¨å·²åœæ­¢');

      // å…³é—­æ–‡ä»¶æµå¹¶æ›´æ–° WAV å¤´éƒ¨
      if (_fileSink != null) {
        debugPrint('ğŸ” [AUDIO] 7. å…³é—­æ–‡ä»¶æµ, å·²å†™å…¥: $_totalBytesWritten bytes');
        await _fileSink!.close();
        _fileSink = null;
        debugPrint('ğŸ” [AUDIO] 8. æ–‡ä»¶æµå·²å…³é—­');

        // æ›´æ–° WAV å¤´éƒ¨ä¸­çš„æ–‡ä»¶å¤§å°
        if (_currentRecordingPath != null) {
          debugPrint('ğŸ” [AUDIO] 9. æ›´æ–° WAV å¤´éƒ¨');
          await _updateWavHeader(_currentRecordingPath!, _totalBytesWritten);
          debugPrint('ğŸ” [AUDIO] 10. WAV å¤´éƒ¨å·²æ›´æ–°');
          print('â¹ å½•éŸ³å·²åœæ­¢: $_currentRecordingPath');
          print('   æ—¶é•¿: ${_recordingDuration.inMinutes}:${(_recordingDuration.inSeconds % 60).toString().padLeft(2, '0')}');
          print('   æ–‡ä»¶å¤§å°: ${(_totalBytesWritten / 1024 / 1024).toStringAsFixed(2)} MB');
        }
      }

      // æ¸…ç©ºç¼“å†²åŒº
      _pcmBuffer.clear();
      _audioBuffer.clear();
      _totalBytesWritten = 0;
      debugPrint('ğŸ” [AUDIO] 11. ç¼“å†²åŒºå·²æ¸…ç©º');

      notifyListeners();
      debugPrint('ğŸ” [AUDIO] 12. stopRecording å®Œæˆ');
      return _currentRecordingPath;
    } catch (e, stack) {
      print('âŒ åœæ­¢å½•éŸ³å¤±è´¥: $e');
      debugPrint('âŒ å †æ ˆ: $stack');
      _isRecording = false;
      _isPaused = false;
      _pcmBuffer.clear();
      _audioBuffer.clear();
      await _fileSink?.close();
      _fileSink = null;
      notifyListeners();
      return null;
    }
  }

  /// æ›´æ–° WAV æ–‡ä»¶å¤´éƒ¨çš„å¤§å°ä¿¡æ¯
  Future<void> _updateWavHeader(String path, int dataSize) async {
    debugPrint('ğŸ” [WAV] å¼€å§‹æ›´æ–° WAV å¤´éƒ¨: $path, dataSize: $dataSize');
    try {
      final file = File(path);

      // å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
      if (!await file.exists()) {
        debugPrint('âŒ [WAV] æ–‡ä»¶ä¸å­˜åœ¨: $path');
        return;
      }

      final fileSize = await file.length();
      debugPrint('ğŸ” [WAV] å½“å‰æ–‡ä»¶å¤§å°: $fileSize bytes');

      // è¯»å–æ•´ä¸ªæ–‡ä»¶
      final bytes = await file.readAsBytes();
      debugPrint('ğŸ” [WAV] æ–‡ä»¶å·²è¯»å–åˆ°å†…å­˜');

      // åˆ›å»º ByteData è§†å›¾æ¥ä¿®æ”¹
      final byteData = ByteData.sublistView(bytes);

      // æ›´æ–° RIFF chunk å¤§å° (ä½ç½® 4)
      byteData.setUint32(4, 36 + dataSize, Endian.little);
      debugPrint('ğŸ” [WAV] RIFF å¤§å°å·²æ›´æ–°: ${36 + dataSize}');

      // æ›´æ–° data chunk å¤§å° (ä½ç½® 40)
      byteData.setUint32(40, dataSize, Endian.little);
      debugPrint('ğŸ” [WAV] Data å¤§å°å·²æ›´æ–°: $dataSize');

      // å†™å›æ–‡ä»¶
      await file.writeAsBytes(bytes);
      debugPrint('ğŸ” [WAV] WAV å¤´éƒ¨æ›´æ–°å®Œæˆ');

      // éªŒè¯æ–‡ä»¶
      final updatedSize = await file.length();
      debugPrint('ğŸ” [WAV] éªŒè¯æ–‡ä»¶å¤§å°: $updatedSize bytes');
    } catch (e, stack) {
      debugPrint('âŒ [WAV] æ›´æ–° WAV å¤´éƒ¨å¤±è´¥: $e');
      debugPrint('âŒ [WAV] å †æ ˆ: $stack');
    }
  }

  /// å–æ¶ˆå½•éŸ³
  Future<void> cancelRecording() async {
    if (!_isRecording) return;

    try {
      // åœæ­¢æµè®¢é˜…
      await _streamSubscription?.cancel();
      _streamSubscription = null;

      await _recorder.stop();

      // å…³é—­æ–‡ä»¶æµ
      await _fileSink?.close();
      _fileSink = null;

      // åˆ é™¤å½•éŸ³æ–‡ä»¶
      if (_currentRecordingPath != null) {
        final file = File(_currentRecordingPath!);
        if (await file.exists()) {
          await file.delete();
        }
      }

      _isRecording = false;
      _isPaused = false;
      _currentRecordingPath = null;
      _recordingDuration = Duration.zero;
      _pcmBuffer.clear();
      _audioBuffer.clear();
      _totalBytesWritten = 0;

      _stopDurationTimer();
      _stopAudioLevelMonitor();

      print('âœ— å½•éŸ³å·²å–æ¶ˆ');
      notifyListeners();
    } catch (e) {
      print('âŒ å–æ¶ˆå½•éŸ³å¤±è´¥: $e');
    }
  }

  /// å¯åŠ¨æ—¶é•¿è®¡æ—¶å™¨
  void _startDurationTimer() {
    _durationTimer = Timer.periodic(const Duration(seconds: 1), (timer) {
      if (_recordingStartTime != null) {
        _recordingDuration = DateTime.now().difference(_recordingStartTime!);
        notifyListeners();
      }
    });
  }

  /// åœæ­¢æ—¶é•¿è®¡æ—¶å™¨
  void _stopDurationTimer() {
    _durationTimer?.cancel();
    _durationTimer = null;
  }

  /// å¯åŠ¨éŸ³é¢‘ç”µå¹³ç›‘æ§
  void _startAudioLevelMonitor() {
    // éŸ³é¢‘ç”µå¹³ç°åœ¨ä»éŸ³é¢‘æ ·æœ¬ä¸­ç›´æ¥è®¡ç®—
    // è¿™é‡Œåªå¯åŠ¨ä¸€ä¸ªå®šæ—¶å™¨æ¥å®šæœŸé€šçŸ¥ UI æ›´æ–°
    _levelTimer = Timer.periodic(const Duration(milliseconds: 100), (timer) {
      if (!_isRecording || _isPaused) {
        _audioLevel = 0;
        notifyListeners();
      }
    });
  }

  /// åœæ­¢éŸ³é¢‘ç”µå¹³ç›‘æ§
  void _stopAudioLevelMonitor() {
    _levelTimer?.cancel();
    _levelTimer = null;
    _audioLevel = 0;
    notifyListeners();
  }

  /// æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº
  void clearAudioBuffer() {
    _audioBuffer.clear();
    _pcmBuffer.clear();
  }

  /// è·å–å½•éŸ³æ—¶é•¿
  Duration getRecordingDuration() {
    return _recordingDuration;
  }

  /// æ ¼å¼åŒ–æ—¶é•¿æ˜¾ç¤º
  String get formattedDuration {
    final minutes = _recordingDuration.inMinutes;
    final seconds = _recordingDuration.inSeconds % 60;
    return '${minutes.toString().padLeft(2, '0')}:${seconds.toString().padLeft(2, '0')}';
  }

  /// æ¸…ç†èµ„æº
  @override
  void dispose() {
    _stopDurationTimer();
    _stopAudioLevelMonitor();
    _stateSubscription?.cancel();
    _streamSubscription?.cancel();
    _recorder.dispose();
    _audioStreamController.close();
    super.dispose();
  }
}

/// éŸ³é¢‘æ–‡ä»¶å·¥å…·
class AudioFileUtils {
  /// è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
  static Future<AudioFileInfo?> getAudioInfo(String path) async {
    try {
      final file = File(path);
      if (!await file.exists()) return null;

      final stat = await file.stat();
      final size = stat.size;

      return AudioFileInfo(
        path: path,
        fileSize: size,
      );
    } catch (e) {
      return null;
    }
  }

  /// åˆ é™¤éŸ³é¢‘æ–‡ä»¶
  static Future<bool> deleteAudioFile(String path) async {
    try {
      final file = File(path);
      if (await file.exists()) {
        await file.delete();
        return true;
      }
      return false;
    } catch (e) {
      return false;
    }
  }
}

/// éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
class AudioFileInfo {
  final String path;
  final int fileSize;

  AudioFileInfo({
    required this.path,
    required this.fileSize,
  });

  String get fileSizeFormatted {
    if (fileSize < 1024) {
      return '$fileSize B';
    } else if (fileSize < 1024 * 1024) {
      return '${(fileSize / 1024).toStringAsFixed(1)} KB';
    } else {
      return '${(fileSize / (1024 * 1024)).toStringAsFixed(1)} MB';
    }
  }
}
